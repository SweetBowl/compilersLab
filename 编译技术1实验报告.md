###一、实验名称：使用C语言对Java程序进行词法分析

### 二、实验学时：2学时

### 三、实验目的：

​	以test.java作为输入文件，使用C语言编写程序

​	1.识别程序中所有的整数以及字符串常量

​	2.识别程序中所有符号、标识符及关键字

​	3.将所编写程序命名为"man_lex.c"

###四、实验原理

​	词法分析主要是对源程序进行编译预处理，比如去除注释，无用的回车、换行，找到包含的文件等。之后，对整个源程序进行分解，分解为一个一个语素。语素的描述由程序设计词法定义给出，通常与语言的语法描述分开。程序设计语言的语素包括数字的字面值、运算符、关键字、界符、标识符等。可以说，词法分析面向的对象是单个的字符，目的是把它们组成有效的单词。

###五、实验内容：

下面是本实验的子集以及对应的种别码

​	**第一类：关键字(50)**

​	种别码从1开始，往后一次顺延至50

```C++
char keyword[50][13]={"abstract","assert","boolean","break","byte","case","catch","char",
 "class","const","continue","default","do","double","else","enum","extends","final","finally","float","for","if","goto","implements","import","instanceof","int","interface","long","native","new","package","private","protected","public","return","short","static","strictfp","super","switch","synchronized","this","throw","throws","transient","try","void","volatile","while"}
```

​	**第二类：符号(47)**

​	a.不是某字符前缀的符号(13)

​	种别码从51开始，往后依次顺延至63

```C++
const char monoOperator[13]={'(',')','[',']','{','}',';',',','.','?',':','~','\''};
```

​	b.是某字符前缀的符号(12)

​	种别码从64开始，往后依次顺延至75

```C++
const char speOperator[12]={'=','<','>','+','','!','*','%','/','&','|','^'};
```

​	c.多目符(22)

​	种别码从76开始，往后依次顺延至97

```C++
const char binocularOperator[22][5]={"==","<=","<<=","<<",">=",">>",">>>",">>=",">>>=","+=","++","--","-=","!=","*=",
    "%=","/=","&=","&&","|=","||","^=",};
```

​	**第三类：常数**

​	种别码98

​	**第四类：标识符**

​	种别码99

```C++
static char identifierTb[numID][30]={""};        //标识符表
```

​	**第五类：特殊的@开头的字符**

​	种别码100

​	**第六类：字符串**

​	种别码101

### 六、实验器材

个人笔记本电脑

实验环境：系统macOS Catalina 10.15

### 七、实验步骤

​	函数总览:bool isLetter(char letter), bool isDigit(), int searchKey(char keyword\[][13], char s []), int infoInit(char resourceProj[numChar]), void filterPro(char ch[],int lenResource), bool checkLetter(char resourceProj[], char token[],int &cur,int &count, int &syn), bool checkDigit(char resourceProj[],char token[],int &cur,int &count, int &syn), bool checkMono(char resourceProj[], char token[], int &cur, char ch, int &syn), bool checkBino(char resourceProj[], char token[], int &cur, int &syn),bool checkString(char resourceProj[], int &cur, char tmps[],int &syn), void lexer(int &syn, char resourceProj[], char token[],int &cur,FILE *fp),int main(int args, const char *argv[])

1.头文件与宏声明

```C++
#include <stdio.h>
#include <ctype.h>
#include <string.h>
#include <stdlib.h>

#define numChar 10000
#define numKey 50
#define nummono 13
#define numspe 12
#define numbino 22
#define constSyn 98
#define liberSyn 99
#define lenToken 50
#define numID 1000

using namespace std;
```



2.词法分析程序首先打开源文件，读取文件内容到数组中，直至文件末尾，读取结束。

```C++
int infoInit(char resourceProj[numChar]){
    
    FILE *fp;
    int cur=0;
  //此处使用绝对路径
    if ((fp=fopen("/Users/zhaoxu/Downloads/编译_lab1/test.java", "r"))==NULL) {
        printf("无法打开文件\n");
        return 0;
    }
    
    //初始化数组
     for (int j=0; j<numChar; j++) {
         resourceProj[j]='\0';
     }
    
    //在未到达文件尾的情况下将文件内容读取到数组中
    resourceProj[cur] = fgetc(fp);
    while (!feof(fp)) {
        cur++;
        resourceProj[cur] = fgetc(fp);
    }
    resourceProj[++cur]='\0';
    
    return cur;
}
```



3.编译预处理：对读取的文件进行预处理。从头到尾扫描，去除// 和/* */的内容，但是此时不去除空格，并将处理后的结果存到数组中

```C++
void filterPro(char ch[],int lenResource)
{
    char temString[numChar];
    int count=0;
    
    for (int i=0; i<=lenResource; i++) {
//        单行注释'//'，去除注释后面的东西，直到换行
        if (ch[i] =='/' && ch[i+1]=='/') {
            while (ch[i]!='\n') {
                i++;
            }
        }
        if (ch[i]=='/'&&ch[i+1]=='*') {
//         多行注释'/*'，去除注释后面的东西，直到遇到'*/'
            i += 2;
            while (ch[i]!='*'||ch[i+1]!='/') {
                i++;
            }
            i += 2;
            
        }
        if (ch[i] !='\n' && ch[i]!='\t' && ch[i]!='\r') {
//            过滤掉无用字符，存到数组中
            temString[count++]=ch[i];
        }
    }
    
    temString[count] ='\0';
    strcpy(ch, temString);
}
```



​    4.对源文件从头到尾进行扫描了。本程序将文件中的内容读取到一个大数组char resourceProj[numChar]中。之后对这个数组从头开始扫描。首先要过滤空格，若是空格，则继续扫描下一个字符，直至不是空格。然后依次询问这个字符是不是字母，若是则进行标识符和关键字的识别；若这个字符为数字，则进行数字的判断；若这个字符为单目符，多目符，则在查询对应的种别码，并打印出内容；最后判断这个单词是不是字符串。若将所有可能都走了一遍还是没有知道它是谁，则认定为错误符号，程序结束。每次成功识别了一个单词后，单词都会存在token[ ]中。这就是扫描程序lexer()进行的工作。可以说这个程序彻底实现了确定有限自动机某些功能，比如说识别标识符，识别数字等。为了简单起见，这里的数字只是整数。

(1).判断是否为字母

```C++
bool isLetter(char letter)
{
    if((letter >='a' && letter<='z') || (letter>='A'&&letter<='Z'))
    {
        return true;
    }
    else
    {
        return false;
    }
}
```

(2).判断是否为数字

```C++
bool isDigit(char digit)
{
    if(digit>='0'&&digit<='9')
    {
        return true;
    }
    else
    {
        return false;
    }
}
```

(3).查找关键字

```C++
int searchKey(char keyword[][13],char s[])
{
    for(int i=0;i<50;i++){
        if (strcmp(keyword[i], s)==0) {
            return i+1;                 //成功查找返回种别码
        }
    }
    return 0;                          //查找不成功返回0
}
```

(4).判断是否为标识符或者关键字

```C++
bool checkLetter(char resourceProj[],char token[],int &cur,int &count,int &syn){
    syn = 0;
    if (isLetter(resourceProj[cur])|| resourceProj[cur] =='_' || resourceProj[cur]=='$') {
        token[count++] = resourceProj[cur];
        cur++;
//        读取后面的字母或数字或特殊字符
        while (isLetter(resourceProj[cur]) || isDigit(resourceProj[cur]) ||resourceProj[cur] =='_' ||resourceProj[cur] =='$') {
            token[count++] =resourceProj[cur];
            cur++;
        }
        token[count]='\0';
//        判断是否为关键字
        syn = searchKey(keyword, token);
        if (syn == 0) {
//            此单词为标识符
            syn =liberSyn;
        }
    }
    else if(resourceProj[cur]=='@'){
        token[count++]=resourceProj[cur];
        cur++;
        while (resourceProj[cur] != 'p'&& resourceProj[cur] !='\n') {
            token[count++]=resourceProj[cur];
            cur++;
        }
        token[count]='\0';
        syn=100;
    }
    return syn;
}
```

(5).判断是否为常数

```C++
bool checkDigit(char resourceProj[],char token[],int &cur,int &count,int &syn){
    syn=0;
    if (isDigit(resourceProj[cur])) {
            while (isDigit(resourceProj[cur])) {
            token[count++] = resourceProj[cur];
            cur++;
        }
        token[count]='\0';
        syn = constSyn;
    }
    return syn;
}
```

(6).判断是不是某字符前缀的单目符

```C++
bool checkMono(char resourceProj[],char token[],int &cur,char ch,int &syn){
    syn = 0;
    if (ch =='('||ch==')'||ch=='['||ch==']'||ch=='{'||ch=='}'||ch==';'||ch==','||ch=='.'||ch=='!'
        ||ch=='?'||ch==':'||ch=='^'||ch=='~'||ch=='\'') {
        token[0] = resourceProj[cur];
        token[1] = '\0';
        for (int i=0; i<nummono; i++) {
            if (resourceProj[cur] == monoOperator[i]) {
                syn = numKey+1+i;
                break;
            }
        }
        cur++;
    }
    return syn;
}
```

(7).判断是否为多目符或者为某字符前缀的单目符

```C++
bool checkBino(char resourceProj[],char token[],int &cur,int &syn){
    syn=0;
    int i=0;
    if (resourceProj[cur] == '=') {
        //判断是否为 = 或者 ==
        token[i]=resourceProj[cur];
        cur++;      //超前搜索
        i++;
        if (resourceProj[cur]=='=') {
            syn = 76;
            token[i]=resourceProj[cur];
        }
        else{
            cur--;  //回退
            syn =64;
        }
        cur++;
        return syn;
    }
    else if (resourceProj[cur]=='<') {
        //判断是否为< 或者 <= 或者 << 或者 <<=
        token[i]=resourceProj[cur];
        cur++;
        i++;
        if (resourceProj[cur]=='=') {
            syn =77;
            token[i]=resourceProj[cur];
        }
        else if(resourceProj[cur] =='<'){
            token[i]=resourceProj[cur];
            cur++;
            i++;
            if (resourceProj[cur]=='=') {
                token[i]=resourceProj[cur];
                syn=79;
            }
            else
            {
                cur--;
                syn=78;
            }
        }
        else
        {
            cur--;
            syn = 65;
        }
        cur++;
        return syn;
    }
    else if(resourceProj[cur]=='>'){
        //>, >=, >>, >>=, >>>, >>>=
        token[i]=resourceProj[cur];
        cur++;
        i++;
        if (resourceProj[cur]=='=') {
            token[i]=resourceProj[cur];
            syn=80;
        }
        else if(resourceProj[cur]=='>')
        {
            token[i]=resourceProj[cur];
            cur++;
            i++;
            if (resourceProj[cur]=='>') {
                token[i]=resourceProj[cur];
                cur++;
                i++;
                if (resourceProj[cur]=='=') {
                    syn=84;
                }
                else
                {
                    cur--;
                    syn=82;
                }
            }
            else if(resourceProj[cur]=='=')
            {
                syn=83;
            }
            else
            {
                cur--;
                syn=81;
            }
        }
        else
        {
            cur--;
            syn=66;
        }
        cur++;
        return syn;
    }
    else if(resourceProj[cur]=='+'){
        token[i]=resourceProj[cur];
        cur++;
        i++;
        if (resourceProj[cur]=='=') {
            token[i]=resourceProj[cur];
            syn=85;
        }
        else if(resourceProj[cur]== '+'){
            token[i]=resourceProj[cur];
            syn = 86;
        }
        else{
            cur--;
            syn=67;
        }
        cur++;
        return syn;
    }
    else if(resourceProj[cur]=='-'){
        token[i]=resourceProj[cur];
        cur++;
        i++;
        if (resourceProj[cur]=='=') {
            token[i]=resourceProj[cur];
            syn=88;
        }
        else if(resourceProj[cur]=='-'){
            token[i]=resourceProj[cur];
            syn=97;
        }
        else{
            cur--;
            syn=68;
        }
        cur++;
        return syn;
    }
    else if(resourceProj[cur]=='!'){
        token[i]=resourceProj[cur];
        cur++;
        i++;
        if (resourceProj[cur]=='=') {
            token[i]=resourceProj[cur];
            syn=89;
        }
        else{
            cur--;
            syn=69;
        }
        cur++;
        return syn;
    }
    else if(resourceProj[cur]=='*'){
        token[i]=resourceProj[cur];
        cur++;
        i++;
        if (resourceProj[cur]=='=') {
            token[i]=resourceProj[cur];
            syn=90;
        }
        else{
            cur--;
            syn=70;
        }
        cur++;
        return syn;
    }
    else if(resourceProj[cur]=='%'){
        token[i]=resourceProj[cur];
        cur++;
        i++;
        if (resourceProj[cur]=='=') {
            token[i]=resourceProj[cur];
            syn=91;
        }
        else{
            cur--;
            syn=71;
        }
        cur++;
        return syn;
    }
    else if(resourceProj[cur]=='/'){
        token[i]=resourceProj[cur];
        cur++;
        i++;
        if (resourceProj[cur]=='=') {
            token[i]=resourceProj[cur];
            syn=92;
        }
        else{
            cur--;
            syn=72;
        }
        cur++;
        return syn;
    }
    else if(resourceProj[cur]=='&'){
        token[i]=resourceProj[cur];
        cur++;
        i++;
        if (resourceProj[cur]=='=') {
            token[i]=resourceProj[cur];
            syn=93;
        }
        else if(resourceProj[cur]=='&'){
            token[i]=resourceProj[cur];
            syn=94;
        }
        else{
            cur--;
            syn=73;
        }
        cur++;
        return syn;
    }
    else if(resourceProj[cur]=='|'){
        token[i]=resourceProj[cur];
        cur++;
        i++;
        if (resourceProj[cur]=='=') {
            token[i]=resourceProj[cur];
            syn=95;
        }
        else if(resourceProj[cur]=='|'){
            token[i]=resourceProj[cur];
            syn=96;
        }
        else{
            cur--;
            syn=74;
        }
        cur++;
        return syn;
    }
    else if(resourceProj[cur]=='^'){
        token[i]=resourceProj[cur];
        cur++;
        i++;
        if (resourceProj[cur]=='=') {
            token[i]=resourceProj[cur];
            syn=97;
        }
        else{
            cur--;
            syn=75;
        }
        cur++;
        return syn;
    }
    //上述条件都没有退出本函数时，返回0
    return syn;
}
```

(8).判断是否为字符串

```C++
bool checkString(char resourceProj[],int &cur,char tmps[],int &syn){
    syn=0;
    int j=0;
    
    if (resourceProj[cur]=='\"') {
        tmps[j]=resourceProj[cur];
        cur++;
        j++;
        
        while (resourceProj[cur] != '\"') {
            tmps[j]=resourceProj[cur];
            cur++;
            j++;
        }
        tmps[j]=resourceProj[cur];
        syn=101;
        cur++;
    }
    return syn;
}
```

(9).完整的词法分析主体

```C++
void lexer(int &syn,char resourceProj[],char token[],int &cur,FILE *fp){
    int i,count = 0;
    int a=0;
    char ch;
    ch = resourceProj[cur];
    
    while (ch == ' ') {
//        过滤空格
        cur++;
        ch = resourceProj[cur];
    }

//        数组初始化
    for (i =0; i<lenToken; i++) {
        token[i] = '\0';
    }
    
    if (checkLetter(resourceProj, token, cur, count, a)) {
        syn  = a;
    }
    else if (checkDigit(resourceProj, token, cur, count, a)) {
        syn = a;
    }
    else if(checkMono(resourceProj, token, cur, ch, a)){
        syn =a;
    }
    else if(checkBino(resourceProj,token,cur, a)){
        syn =a;
    }
    else if(checkString(resourceProj, cur, token,a)){
        syn=a;
    }
    else if(feof(fp)){
//        读到文件末尾
        syn = -1;
    }
    else{
//        若不能被以上词法分析识别，则出错
        printf("Error：不存在%c\n",ch);
        exit(0);
    }
}

```



 4.main()程序主要负责对每次识别的种别码syn进行判断，对于不同的单词种别做出不同的反应，如对于标识符则将其插入标识符表中。对于关键字则输出该关键字的种别码和助记符，等等吧。直至遇到syn=-1，程序结束。

```C++
int main(int argc, const char * argv[]) {
    
    char resourceProj[numChar];
    char token[lenToken]={0};
    int i=0;                //用来指示当前位置
    int j=0,k=0,m=0;                //用来测试输出结果
    int syn=0;             //初始化种别码
    int lenResource=0;
    
    FILE *fp;
    //Users/zhaoxu/Hej.java
    ///Users/zhaoxu/Downloads/编译_lab1/test.java
    fp=fopen("/Users/zhaoxu/Downloads/编译_lab1/test.java", "r");
    
    lenResource=infoInit(resourceProj);
    
    /*
    //测试读取到的内容
    while (resourceProj[i]!='\0') {
        printf("%c ",resourceProj[i]);
        i++;
    }
    printf("\n");
     */
    
    filterPro(resourceProj, lenResource);
    
    /*
    //测试过滤后的内容
    while (resourceProj[j]!='\0') {
        printf("%c ",resourceProj[j]);
     
        j++;
    }
    printf("\n");
     */
    
    printf("对程序文件进行词法分析\n");
    i=0;                    //从头开始读
    while (syn!=-1) {
        lexer(syn, resourceProj, token, i, fp);
//        识别为标识符
        if (syn ==99) {
            for (k=0; k<numID; k++) {
//                标识符已在表格中
                if (strcmp(identifierTb[k], token)==0) {
                    break;
                }
            }
            if (k==numID) {
                for (m=0; m<numID; m++) {
//                若不在表格中，寻找空位，并插入其中
                    if (strcmp(identifierTb[k], "")==0) {
                        strcpy(identifierTb[k], token);
                        break;
                    }
                }
            }
            printf("<标识符99, %s>\n",token);
        }
//        识别为关键字
        else if(syn>=1 && syn<=50){
            printf("<%d, %s>\n",syn,keyword[syn-1]);
        }
        else if(syn ==98){
            printf("<常数98, %s>\n",token);
        }
        else if(syn>=51 && syn<=97)
        {
            printf("<%d, %s>\n",syn,token);
        }
        else if(syn ==100)
        {
            printf("<100, %s>\n",token);
        }
        else if(syn==101)
        {
            printf("<字符串101, %s>\n",token);
        }
    }
    fclose(fp);

    return 0;
}

```

### 八、实验结果与分析

​	程序运行结果如下。词法分析器通常负责符号表的创建，符号表中的记录存储了标识符（用户自定义的名字）的信息，以及标识符（名字）的属性。例如，如果是变量名，那么变量的类型是它存储在符号表中的一个属性，标识符通常由词法分析器放到符号表中，名字的属性通常在词法分析处理之后，由编译器的某个部分放到符号表中。

![截屏2019-11-09下午9.05.54](/Users/zhaoxu/Desktop/截屏2019-11-09下午9.05.54.png)



### 一：实验名称：用Flex实现自动Java程序的词法分析

### 二、实验学时：2学时

### 三、实验目的：

​	1.通过对Flex基本知识的阅读，了解其工作原理和过程以及其匹配模式和规则，掌握简单的Lex语法和规则；

​	2.在上述基础上能够自主编写出简单且可以运行的词法分析器，实现简单的词法分析功能； 

​	3.通过实验，设计编制调试一个具体的词法分析程序，加深对词法分析原理的理解，并掌握在对程序设计语言源程序进行扫描过程中将其分解为各类单词的词法分析方法。

### 四、实验原理：

​	Flex是Lex的一个替代品，经常和开源语法分析器Bison一起使用。Flex最初是由Vern Paxson于1987年用C语言编写。Flex是一个生成扫描器的工具，能够识别文本中的词法模式。Flex读入给定的输入文件，如果没有给定文件名的话，则从标准输入读取，从而获得一个关于需要生成的扫描器的描述。此描述称为规则，由正则表达式和C代码对组成。Flex的输出是一个C代码文件lex.yy.c，其中定义了yylex()函数。编译输出文件并且和-lfl库链接生成一个可执行文件。当运行可执行文件的时候，它分析输入文件，为每一个正则表达式寻找匹配。当发现一个匹配时，它执行与此正则表达式相关的C代码。

​	**Flex全局变量**
  	yytext，char*, 指向所识别的字符串
 	 yyleng，int, 所识别字符串的长度
  	yylval，YYSTYPE, 缺省类型是int
​          	用来保存词法记号的属性
​	标准动作: ECHO  显示所识别的串

#### 1.Lex的介绍

​	Lex是一个词法分析器的生成工具。它支持使用正则表达式来描述各个词法单元的模式，由此给出一个词法分析器的规约。Lex工具的输入表示方法称为Lex语言（Lex language），而工具本身则称为Lex编译器（Lex compiler）。在它的核心部分，Lex编译器讲输入的模式转换成一个状态转换图，并生成相应的实验代码，存放到文件lex.yy.c中，这些代码模拟了状态转换图。

#### 2.Lex源文件格式

Lex对源文件的格式要求非常严格，比如若将要求顶行书写的语句变成非顶行书写就会产生致命错误。而LEX本身的查错能力很弱，所以书写时一定要注意。LEX的源文件由三个部份组成，每个部分之间用顶行的“%%”分割，其格式如下：

定义部份 

%% 
规则部份  

%% 
用户附加C语言部份

#### 3.正则表达式介绍

​	正则表达式是一种用来描述某些字符串的简单集合的很有用的工具。 正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。 

​	字母表是一个有限的符号集合。符号的典型例子包括字母、数位和标点符号。某个字母表上的串是该字母表中符号的一个有穷序列。语言是某给给定的字母表上一个任意可数的串集合，字符串是符号的有限序列，符号本身来自有限字母表。

​	以下表格是正则表达式的全部规则。而常用的为以下几条
[0-9] 字符集：0|1|2|3|4|5|6|7|8|9
​      例如：[0-9A-Za-z]，[aeiou0-9]
^     字符集的补集，需要是字符集中第一个字符 
​      例如：[^0-9] 匹配任何非数字字符
.     匹配“换行符”之外的任何字符
x?    x 可重复 0次 或 1次
x+    x 需重复 至少1次

| 元字符        | 描述                                                         |
| ------------- | ------------------------------------------------------------ |
| \             | 将下一个字符标记符、或一个向后引用、或一个八进制转义符。例如，“\n”匹配\n。“\n”匹配换行符。序列“\”匹配“\”而“(”则匹配“(”。即相当于多种编程语言中都有的“转义字符”的概念。 |
| ^             | 匹配输入字行首。如果设置了RegExp对象的Multiline属性，^也匹配“\n”或“\r”之后的位置。 |
| $             | 匹配输入行尾。如果设置了RegExp对象的Multiline属性，$也匹配“\n”或“\r”之前的位置。 |
| *             | 匹配前面的子表达式任意次。例如，zo*能匹配“z”，也能匹配“zo”以及“zoo”。*等价于{0,}。 |
| +             | 匹配前面的子表达式一次或多次(大于等于1次）。例如，“zo+”能匹配“zo”以及“zoo”，但不能匹配“z”。+等价于{1,}。 |
| ?             | 匹配前面的子表达式零次或一次。例如，“do(es)?”可以匹配“do”或“does”。?等价于{0,1}。 |
| {n}           | *n*是一个非负整数。匹配确定的*n*次。例如，“o{2}”不能匹配“Bob”中的“o”，但是能匹配“food”中的两个o。 |
| {*n*,}        | *n*是一个非负整数。至少匹配*n*次。例如，“o{2,}”不能匹配“Bob”中的“o”，但能匹配“foooood”中的所有o。“o{1,}”等价于“o+”。“o{0,}”则等价于“o*”。 |
| {*n*,*m*}     | *m*和*n*均为非负整数，其中*n*<=*m*。最少匹配*n*次且最多匹配*m*次。例如，“o{1,3}”将匹配“fooooood”中的前三个o为一组，后三个o为一组。“o{0,1}”等价于“o?”。请注意在逗号和两个数之间不能有空格。 |
| ?             | 当该字符紧跟在任何一个其他限制符（*,+,?，{*n*}，{*n*,}，{*n*,*m*}）后面时，匹配模式是非贪婪的。非贪婪模式尽可能少地匹配所搜索的字符串，而默认的贪婪模式则尽可能多地匹配所搜索的字符串。例如，对于字符串“oooo”，“o+”将尽可能多地匹配“o”，得到结果[“oooo”]，而“o+?”将尽可能少地匹配“o”，得到结果 ['o', 'o', 'o', 'o'] |
| .点           | 匹配除“\n”和"\r"之外的任何单个字符。要匹配包括“\n”和"\r"在内的任何字符，请使用像“[\s\S]”的模式。 |
| (pattern)     | 匹配pattern并获取这一匹配。所获取的匹配可以从产生的Matches集合得到，在VBScript中使用SubMatches集合，在JScript中则使用$0…$9属性。要匹配圆括号字符，请使用“(”或“)”。 |
| (?:pattern)   | 非获取匹配，匹配pattern但不获取匹配结果，不进行存储供以后使用。这在使用或字符“(\|)”来组合一个模式的各个部分时很有用。例如“industr(?:y\|ies)”就是一个比“industry\|industries”更简略的表达式。 |
| (?=pattern)   | 非获取匹配，正向肯定预查，在任何匹配pattern的字符串开始处匹配查找字符串，该匹配不需要获取供以后使用。例如，“Windows(?=95\|98\|NT\|2000)”能匹配“Windows2000”中的“Windows”，但不能匹配“Windows3.1”中的“Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 |
| (?!pattern)   | 非获取匹配，正向否定预查，在任何不匹配pattern的字符串开始处匹配查找字符串，该匹配不需要获取供以后使用。例如“Windows(?!95\|98\|NT\|2000)”能匹配“Windows3.1”中的“Windows”，但不能匹配“Windows2000”中的“Windows”。 |
| (？<=pattern) | 非获取匹配，反向肯定预查，与正向肯定预查类似，只是方向相反。例如，“(?<=95\|98\|NT\|2000)Windows”能匹配“2000Windows”中的“Windows”，但不能匹配“3.1Windows”中的“Windows”。*python的正则表达式没有完全按照正则表达式规范实现，所以一些高级特性建议使用其他语言如java、scala等 |
| (?<!patte_n)  | 非获取匹配，反向否定预查，与正向否定预查类似，只是方向相反。例如“(?<!95\|98\|NT\|2000)Windows”能匹配“3.1Windows”中的“Windows”，但不能匹配“2000Windows”中的“Windows”。 |
| x\|y          | 匹配x或y。例如，“z\|food”能匹配“z”或“food”(此处请谨慎)。“[z\|f]ood”则匹配“zood”或“food”。 |
| [xyz]         | 字符集合。匹配所包含的任意一个字符。例如，“[abc]”可以匹配“plain”中的“a”。 |
| [^xyz]        | 负值字符集合。匹配未包含的任意字符。例如，“abc”可以匹配“plain”中的“plin”任一字符。 |
| [a-z]         | 字符范围。匹配指定范围内的任意字符。例如，“[a-z]”可以匹配“a”到“z”范围内的任意小写字母字符。注意:只有连字符在字符组内部时,并且出现在两个字符之间时,才能表示字符的范围; 如果出字符组的开头,则只能表示连字符本身. |
| [^a-z]        | 负值字符范围。匹配任何不在指定范围内的任意字符。例如，“a-z”可以匹配任何不在“a”到“z”范围内的任意字符。 |
| \b            | 匹配一个单词的边界，也就是指单词和空格间的位置（即正则表达式的“匹配”有两种概念，一种是匹配字符，一种是匹配位置，这里的\b就是匹配位置的）。例如，“er\b”可以匹配“never”中的“er”，但不能匹配“verb”中的“er”；“\b1*”可以匹配“1_23”中的“1*”，但不能匹配“21_3”中的“1_”。 |
| \B            | 匹配非单词边界。“er\B”能匹配“verb”中的“er”，但不能匹配“never”中的“er”。 |
| \cx           | 匹配由x指明的控制字符。例如，\cM匹配一个Control-M或回车符。x的值必须为A-Z或a-z之一。否则，将c视为一个原义的“c”字符。 |
| \d            | 匹配一个数字字符。等价于[0-9]。grep 要加上-P，perl正则支持   |
| \D            | 匹配一个非数字字符。等价于0-9。grep要加上-P，perl正则支持    |
| \f            | 匹配一个换页符。等价于\x0c和\cL。                            |
| \n            | 匹配一个换行符。等价于\x0a和\cJ。                            |
| \r            | 匹配一个回车符。等价于\x0d和\cM。                            |
| \s            | 匹配任何不可见字符，包括空格、制表符、换页符等等。等价于[ \f\n\r\t\v]。 |
| \S            | 匹配任何可见字符。等价于 \f\n\r\t\v。                        |
| \t            | 匹配一个制表符。等价于\x09和\cI。                            |
| \v            | 匹配一个垂直制表符。等价于\x0b和\cK。                        |
| \w            | 匹配包括下划线的任何单词字符。类似但不等价于“[A-Za-z0-9_]”，这里的"单词"字符使用Unicode字符集。 |
| \W            | 匹配任何非单词字符。等价于“A-Za-z0-9_”。                     |
| \x*n*         | 匹配*n*，其中*n*为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，“\x41”匹配“A”。“\x041”则等价于“\x04&1”。正则表达式中可以使用ASCII编码。 |
| \num          | 匹配*num*，其中*num*是一个正整数。对所获取的匹配的引用。例如，“(.)\1”匹配两个连续的相同字符。 |
| \n            | 标识一个八进制转义值或一个向后引用。如果*n*之前至少*n*个获取的子表达式，则*n*为向后引用。否则，如果*n*为八进制数字（0-7），则*n*为一个八进制转义值。 |
| \nm           | 标识一个八进制转义值或一个向后引用。如果*nm*之前至少有*nm*个获得子表达式，则*nm*为向后引用。如果\*nm*之前至少有*n*个获取，则*n*为一个后跟文字*m*的向后引用。如果前面的条件都不满足，若*n*和*m*均为八进制数字（0-7），则*nm*将匹配八进制转义值*nm*。 |
| \nml          | 如果*n*为八进制数字（0-7），且*m*和*l*均为八进制数字（0-7），则匹配八进制转义值*nml*。 |
| \u*n*         | 匹配*n*，其中*n*是一个用四个十六进制数字表示的Unicode字符。例如，\u00A9匹配版权符号（©）。 |
| \p{P}         | 小写 p 是 property 的意思，表示 Unicode 属性，用于 Unicode 正表达式的前缀。中括号内的“P”表示Unicode 字符集七个字符属性之一：标点字符。其他六个属性：L：字母；M：标记符号（一般不会单独出现）；Z：分隔符（比如空格、换行等）；S：符号（比如数学符号、货币符号等）；N：数字（比如阿拉伯数字、罗马数字等）；C：其他字符。**注：此语法部分语言不支持，例：javascript。 |
|               | 匹配词（word）的开始（<）和结束（>）。例如正则表达式<the>能够匹配字符串"for the wise"中的"the"，但是不能匹配字符串"otherwise"中的"the"。注意：这个元字符不是所有的软件都支持的。 |
| ( )           | 将( 和 ) 之间的表达式定义为“组”（group），并且将匹配这个表达式的字符保存到一个临时区域（一个正则表达式中最多可以保存9个），它们可以用 \1 到\9 的符号来引用。 |
| \|            | 将两个匹配条件进行逻辑“或”（or）运算。例如正则表达式(him\|her) 匹配"it belongs to him"和"it belongs to her"，但是不能匹配"it belongs to them."。注意：这个元字符不是所有的软件都支持的。 |

[^注]: 该正则表达式规则表格来源于百度百科

### 五、实验内容：

​	1.阅读所给的Flex文档，熟悉Flex的语法规则。

​	2.在完成1的情况下编写*.l程序完成对integers, strings, identifiers, keywords, operators, comments.等的识别。

​	3.调试写好的程序，使其能够顺利的达到预期目的，即完成对test.java文件的自动词法分析。

### 六、实验器材

1.个人笔记本电脑

2.实验环境：

​	① 下载flex和bison并安装到D:\GnuWin32（尽量是根目录）

​	② 由于我们使用的flex和bison都是GNU的工具，所以为了方便，采用的C/C++

编译器也 采用GNU的编译器GCC，当然我们需要的也是Windows版本的GCC了。

​	③ 检验是否可以进行lex文件编译

​	④在编写Flex源代码的时候使用notepad++编辑器，并将语言类型调到C语言模式。

### 七、实验步骤

#### 1、检验是否可以进行flex文件编译

在这里使用老师提供的calc.l文件进行测试。

​	进入到Windows控制台

​		1.输入flex calc.l

​		2.输入gcc -o scan lex.yy.c -lfl

但是这里会发现发现控制台会报错，错误信息如下

collect2.exe: error: ld returned 1 exit status

解决方法：

​	在文件末尾加入

int yywrap(){
        return 1;
}

​	再次输入时使用gcc -o scan lex.yy.c命令。

发现问题可以完美解决

#### 2、编译针对Java语言的Flex词法分析程序

##### 1、系统模块划分

Lex 工具是一种词法分析程序生成器，它可以根据词法规则说明书的要求来生成单词识别程序， 由该程序识别出输入文本中的各个单词。一般可以分为<定义部分><规则部分>< 用户子程序部分>。其中规则部分是必须的，定义和用户子程序部分是任选的。

①定义部分：定义部分起始于 %{ 符号，终止于 %} 符号，其间可以是包括 include 语句、声明语句在内的 C 语句。这部分跟普通 C 程序开头没什么区别。

②规则部分：规则部分起始于"%%"符号，终止于"%%"符号，其间则是词法规则。词法规则由模式和动作两部分组成。模式部分可以由任意的正则表达式组成，模式部分可以由任意的正则表达式组成，动作部分是由 C 语言语句组成，这些语句用来对所匹配的模式进行相应处理。需要注意的是，lex 将识 别出来的单词存放在 yytext[]字符数据中，因此该数组的内容就代表了所识别出来的单词 的内容。类似 yytext 这些预定义的变量函数会随着后面内容展开一一介绍。动作部分如 果有多行执行语句，也可以用{}括起来。

③用户子程序部分：最后一个%%后面的内容是用户子程序部分，可以包括用C语言编写的子程序，而这些子程序可以用在前面的动作中，这样就可以达到简化编程的目的。

##### 2、Flex代码的设计与实现

Flex实验代码较为简单，在本实验过程中主要是一些简单的重复性编程

###### 辅助定义部分

(1).关键字处理：

```c
ASSERT assert
BOOLEAN boolean
BREAK break
BYTE byte
CASE case
CHAR char
CLASS class
CONST const
CONTINUE continue
DEFAULT default
DO do
DOUBLE double
ELSE esle
EXTENDS extends
FINAL final
FINALLY finally
FLOAT float
FOR for
IF if
GOTO goto
IMPLEMENTS implements
IMPORT import
INSTANCEOF instenceof
INT int
INTERFACE interface
LONG long
NATIVE native
ENUM enum
NEW new
PACKAGE package
PRIVATE private
PROTECTED protected
PUBLIC public
RETURN return
SHORT short
STATIC static
STRICTFP strictfp
SUPER super
SWITCH switch
SYNCHRONIZED synchronized
THIS this
THROW throw
THROWS throws
TRANSIENT traneient
TRY try
VOID void
VOLATILE volatile
WHILE while
```

在这里我将Java语言的关键字全部定义为其对应单词大写的宏

(2).标识符处理

```c
identifier [a-z_A-Z][a-z_A-Z0-9]*
```

这里定义了一个identifier即标识符，只考虑了使用大小写字母和下划线开头的情况，并且里面可以包含大小写字母和数字。

(3).注释处理

```c
comment (\/\/.*)|(\/\*(.|\n)*\/)
```

这里定义了一个comment即注释，考虑了以"//"开头的单行注释和以"/**"开头以"/"结尾的多行注释，而以"/**"开头的文本注释则包含在了以"/*"开头的多行注释中了。

(4).空白符、换行符、制表符等特殊符号处理

```c
whitespace [ \t\n\r\f\v]+
```

这里定义了一个whitespace，用它来表示Java中的一个或多个" "、"\t"、"\n"、"\r"、"\f"、"\v"。

(5).运算符处理

```c
SUB  \-
MUL  \*
QUO  \/
REM  \%
INC    \+\+
DEC    \-\-
ASSIGN  \=
ADD_ASSIGN  \+=
SUB_ASSIGN  \-=
MUL_ASSIGN  \*=
QUO_ASSIGN  \/=
REM_ASSIGN  \%=
AND_ASSIGN  \&=
OR_ASSIGN  \|=
XOR_ASSIGN  \^=
SHL_ASSIGN  \<<r=
SHR_ASSIGN  \>>=
AND_NOT_ASSIGN  \~=
AND      \&
OR       \|
XOR      \^
SHL      \<<
SHR      \>>
LAND   \&\&
LOR    \|\|
NOT    \!
EQL     \==
LSS     \<
GTR     \>
NEQ       \!=
LEQ       \<=
GEQ       \>=
```

这里使用了和关键字处理相同的方法，即将各种预算符声明为相应的宏定义

(6).异常数字处理

```c
excption [0-9][0-9a-zA-Z\.]+
```

这里定义了一个exception用来表示以数字开头但是后面跟着大小写字母的异常情况

```c
floatexcption {decimal}\.[0-9]+([Ee]?[-+]?[0-9]+)?[Uu]
```

(7).在输出部分使用{*} {printf("", yytext);的模式。

###### 识别规则部分

```c
 /*关键字*/
{ABSTRACT} {printf("<   keyword1,%s   >\n", yytext);}
{ASSERT} {printf("<   keyword2,%s   >\n", yytext);}
{BOOLEAN} {printf("<   keyword3,%s   >\n", yytext);}
{BREAK} {printf("<   keyword4,%s   >\n", yytext);}
{BYTE} {printf("<   keyword5,%s   >\n", yytext);}
{CASE} {printf("<   keyword6,%s   >\n", yytext);}
{RETURN} {printf("<   keyword7,%s   >\n", yytext);}
{CHAR} {printf("<   keyword8,%s   >\n", yytext);}
{CLASS} {printf("<   keyword9,%s   >\n", yytext);}
{CONST} {printf("<   keyword10,%s   >\n", yytext);}
{CONTINUE} {printf("<   keyword11,%s   >\n", yytext);}
{DEFAULT} {printf("<   keyword12,%s   >\n", yytext);}
{DO} {printf("<   keyword13 %s   >\n", yytext);}
{DOUBLE} {printf("<   keyword14,%s   >\n", yytext);}
{ELSE} {printf("<   keyword15,%s   >\n", yytext);}
{ENUM} {printf("<   keyword16,%s   >\n", yytext);}
{EXTENDS} {printf("<   keyword17,%s   >\n", yytext);}
{FINAL} {printf("<   keyword18,%s   >\n", yytext);}
{FINALLY} {printf("<   keyword19,%s   >\n", yytext);}
{FLOAT} {printf("<   keyword20,%s   >\n", yytext);}
{FOR} {printf("<   keyword21,%s   >\n", yytext);}
{IF} {printf("<   keyword22,%s   >\n", yytext);}
{GOTO} {printf("<   keyword23,%s   >\n", yytext);}
{IMPLEMENTS} {printf("<   keyword24,%s   >\n", yytext);}
{IMPORT} {printf("<   keyword25,%s   >\n", yytext);}
{INSTANCEOF} {printf("<   keyword26,%s   >\n", yytext);}
{INT} {printf("<   keyword27,%s   >\n", yytext);}
{INTERFACE} {printf("<   keyword28,%s   >\n", yytext);}
{LONG} {printf("<   keyword29,%s   >\n", yytext);}
{NATIVE} {printf("<   keyword30,%s   >\n", yytext);}
{NEW} {printf("<   keyword31,%s   >\n", yytext);}
{PACKAGE} {printf("<   keyword32,%s   >\n", yytext);}
{PRIVATE} {printf("<   keyword33,%s   >\n", yytext);}
{PROTECTED} {printf("<   keyword34,%s   >\n", yytext);}
{PUBLIC} {printf("<   keyword35,%s   >\n", yytext);}
{RETURN} {printf("<   keyword36,%s   >\n", yytext);}
{SHORT} {printf("<   keyword37,%s   >\n", yytext);}
{STATIC} {printf("<   keyword38,%s   >\n", yytext);}
{STRICTFP} {printf("<   keyword39,%s   >\n", yytext);}
{SUPER} {printf("<   keyword40,%s   >\n", yytext);}
{SWITCH} {printf("<   keyword41,%s   >\n", yytext);}
{SYNCHRONIZED} {printf("<   keyword42,%s   >\n", yytext);}
{THIS} {printf("<   keyword43,%s   >\n", yytext);}
{THROW} {printf("<   keyword44,%s   >\n", yytext);}
{THROWS} {printf("<   keyword45,%s   >\n", yytext);}
{TRANSIENT} {printf("<   keyword46,%s   >\n", yytext);}
{TRY} {printf("<   keyword47,%s   >\n", yytext);}
{VOID} {printf("<   keyword48,%s   >\n", yytext);}
{VOLATILE} {printf("<   keyword49,%s   >\n", yytext);}
{WHILE} {printf("<   keyword50,%s   >\n", yytext);}
 /*提前处理浮点数+uU的异常*/
{floatexcption} {printf("Float Execption: %s\n",yytext);} 
 /*异常数字处理*/
{excption} {printf("<   Number Execption,%s   >\n",yytext);}

 /*跳过空白和注释*/
{whitespace} {}
{comment} {printf("This is a commit.\n");}

 /*运算符*/
 /*算术运算符*/
{ADD} {printf("<   operator51,%s   >\n",yytext);}
{SUB} {printf("<   operator52,%s   >\n",yytext);}
{MUL} {printf("<   operator53,%s   >\n",yytext);}
{QUO} {printf("<   operator54,%s   >\n",yytext);}
{REM} {printf("<   operator55,%s   >\n",yytext);}
{INC} {printf("<   operator56,%s   >\n",yytext);}
{DEC} {printf("<   operator57,%s   >\n",yytext);}
 /*逻辑运算符*/
{LAND} {printf("<   operator58,%s   >\n",yytext);}
{LOR} {printf("<   operator59,%s   >\n",yytext);}
{NOT} {printf("<   operator60,%s   >\n",yytext);}
 /*赋值运算符*/
{ASSIGN} {printf("<   operator61,%s   >\n",yytext);}
{ADD_ASSIGN} {printf("<   operator62,%s   >\n",yytext);}
{SUB_ASSIGN} {printf("<   operator63,%s   >\n",yytext);}
{MUL_ASSIGN} {printf("<   operator64,%s   >\n",yytext);}
{QUO_ASSIGN} {printf("<   operator65,%s   >\n",yytext);}
{REM_ASSIGN} {printf("<   operator66,%s   >\n",yytext);}
{AND_ASSIGN} {printf("<   operator67,%s   >\n",yytext);}
{OR_ASSIGN} {printf("<   operator68,%s   >\n",yytext);}
{XOR_ASSIGN} {printf("<   operator69,%s   >\n",yytext);}
{SHL_ASSIGN} {printf("<   operator70,%s   >\n",yytext);}
{SHR_ASSIGN} {printf("<   operator71,%s   >\n",yytext);}
{AND_NOT_ASSIGN} {printf("<   operator72,%s   >\n",yytext);}
 /*位运算符*/
{AND} {printf("<   operator73,%s   >\n",yytext);}
{OR} {printf("<   operator74,%s   >\n",yytext);}
{XOR} {printf("<   operator75,%s   >\n",yytext);}
{SHL} {printf("<   operator76,%s   >\n",yytext);}
{SHR} {printf("<   operator77,%s   >\n",yytext);}
{AND_NOT} {printf("<   operator78,%s   >\n",yytext);}
 /*关系运算符*/
{EQL} {printf("<   operator79,%s   >\n",yytext);}
{LSS} {printf("<   operator80,%s   >\n",yytext);}
{GTR} {printf("<   operator81,%s   >\n",yytext);}
{NEQ} {printf("<   operator82,%s   >\n",yytext);}
{LEQ} {printf("<   operator83,%s   >\n",yytext);}
{GEQ} {printf("<   operator84,%s   >\n",yytext);}
 /*标点符号*/
{LPAREN} {printf("<   punctuation85,%s   >\n",yytext);}
{LBRACK} {printf("<   punctuation86,%s   >\n",yytext);}
{LBRACE} {printf("<   punctuation87,%s   >\n",yytext);}
{COMMA} {printf("<   punctuation88,%s   >\n",yytext);}
{PERIOD} {printf("<   punctuation89,%s   >\n",yytext);}
{RPAREN} {printf("<   punctuation90,%s   >\n",yytext);}
{RBRACK} {printf("<   punctuation91,%s   >\n",yytext);}
{RBRACE} {printf("<   punctuation92,%s   >\n",yytext);}
{SEMICOLON} {printf("<   punctuation93,%s   >\n",yytext);}
{COLON} {printf("<   punctuation94,%s   >\n",yytext);}
{POT} {printf("<   punctuation95,%s   >\n",yytext);}
{DQUA} {printf("<   punctuation96,%s   >\n",yytext);}
{SQUA} {printf("<   punctuation97,%s   >\n",yytext);}
 /*数字表示*/
{number} {printf("<   Number98,%s   >\n",yytext);}
```

###### 用户自定义部分

```c
int main(int argc,char **argv)
{
    yyin = fopen("test.java", "r");
	yylineno = 1;
        yylex();
        return 0;
	fclose(yyin);
	system("pause");
}
```

在该部分实现了用户自定以的程序块，即直接用到生成的lex.yy.c程序中的函数。

### 八、实验结果与分析

以下为本实验的结果

在控制台进行以下形式的输入

![image-20191109203752112](/Users/zhaoxu/Downloads/image-20191109203752112.png)

最终结果如下（仅截取部分结果）

![image-20191109204120912](/Users/zhaoxu/Downloads/image-20191109204120912.png)



### 九、总结与心得体会

​	本次实验中，使用C语言编写Java文件的词法分析器，虽然说在过程中遇到了很多错误，但也因此加深了我们对词法分析原理的理解。这次实验也发现了很多问题，概括来说还是对词法分析过程的不熟悉。一些有代表性的错误在解决过程中我也有了自己的一些理解，整理如下：

​	1.一开始拿到实验题目的时候，没有明确的方向，思路也不清楚。

​	在写实验的过程中，体会到了上课讲到的状态图对实验思路的重要性。状态转换图是有限有向图，结点代表状态，结点间的有向边代表状态之间的转换关系，有向边上标记的字符表示状态转换的条件。图中每一个状态对应一段程序，遇到分支可使用if语句实现，如果分支较多，可采用case语句，遇到回路可采用while语句。实验之前将状态图绘制出来之后，在整个实验编写过程中就流畅的多，最后的debug阶段也能更好地找到代码的问题，是逻辑出错还是语法出错都很好发现。

​	2.这次实验要求使用C语言编写，在面对字符串时，须构建数组来存储字符，和C++中的String函数比起来要麻烦不少。在文件开头，define标识符和常量的最大长度可以一定程度上将程序变得更为简洁。不过和String类比起来容错率和可变更性就没那么强。也正是因为如此，让我们更能体会到C和C++同源和拓展的一面，对语言的运用有了更好的理解。

​	3.关于跳过注释。最初的想法是在扫描的过程中将注释内容赋予一个特殊的种别码，在最后的main函数中通过printf的筛选不输出注释内容。后来考虑到程序执行时这样的处理方法会导致内存的大量占用，而这些占用都是可以避免的。所以在最后有余力的情况下，我们对代码进行了优化。在扫描的过程中遇到注释时，先通过if判断是单行注释还是段落注释，若为单行注释，则直接将指针往后移动，直到遇见回车符为止；若为段落注释，在if中嵌套一个if判断条件，遇到结尾符结束，直接将整段跳过，进入后续的扫描。不需要将注释内容也保存到数组中，剔除了无效内容。一定程度上节约了程序内存，也锻炼了我们思考程序运行内核中的能力。

​	4.在flex编写词法分析器的过程中，包括flex语法都需要我们现学，关于flex中一些独特的函数、指针在这里也想在自己的学习角度总结一下。flex文件的最后，在为生成的分析程序编写main函数时，首先需要通过yyin()来获取指向被分析文件的文件FILE指针，而分析部分的实体在函数yylex()中。最后调用的yywrap()函数用于判断是否已经扫描完了所有的文件。如果它在最后一个文件的末尾被调用，则返回值为1。此时程序将停止分析，可以用来扫描多个文件。不仅局限于在本次实验中的test.java文件。最开始的时候直接调用yywrap()函数，编译出错，一直找不到错误，后来在深入了解yywrap()函数后发现，直接调用yywrap()函数可能会导致yywrap未定义的错误，这个函数必须由用户亲自编写，而函数内容也很简单，返回1即可。

​	5.关于实验的改进，C语言编写词法分析器时，在读取文件时，可将绝对地址改为相对地址，这样在未来更改读取文件和别人运行代码时会更加方便。除此之外，在简化代码方面可以将过滤过程不显示出来，运行之后直接输出词法分析结果，过滤过程单独抽取出来性形成一个单独的函数，在未来的调用过程中针对不同的源文件或者不同的过滤规则能够更好的修改。关于空格的重要性，最开始读取源文件的时候，扫描到空格时，不能把空格跳过或者删除掉，应该把空格保留下来以便实现后续的操作，具体实现过程可见源代码。在flex编写词法分析器的过程中，从简洁代码的方面来看，可以将二进制，十进制，十六进制不做进一步的区分，统一通过常量来替换，虽然在词法分析的方面没有那么细致，但更加简洁，功能也基本相同。

​		通过编译原理课程设计，让我学到了很多东西。首先是加深了对编译原理课程的理解，对词法分析有了更进一步的掌握，其次是编程能力的提高，包括程序编译的原理和庞大的代码量。有了前面课程设计的经验，这一次的编译原理课程设计，我更注重数据结构，数据结构的好坏直接决定了代码的复杂度，代码的量。虽然还没开始做词法分析器和语义分析，但是通过这一段时间写词法分析器我对一个编译器的组成有了更深层次的认识。通过本次的课程设计，我对自动机有了更深入的了解，也希望这些理论会再我们日后的学习中发挥更大的作用。总而言之，通过这次具体的操作，在不断的犯错过程中强化了自己代码方面的能力和实现各类功能的思维，受益良多！



### 十、对本实验过程及方法、手段的改进建议：

#### 1、关键字等的处理

​	在这次实验中关键字等的处理我是用了每一个关键字一个printf语句的模式，这就使得整个代码显得比较繁琐、冗长。究其原因是我自己在flex语言的换行处理不是很了解，再加上要对其进行种别码加一的处理，这也让我最开始有一点无从下手，所以限于自己的水平有限就选择了这样的方式。回过头来看，我觉得这是整个实验过程中最需要改进的地方。

#### 2、正则表达式的使用不是很熟悉

​	在实验过程中，比如标识符、数字、注释、字符串等的处理都会使用到正则表达式。但是在实际操作过程中却也是遇到了一些困难，特别是在字符串的处理的时候

